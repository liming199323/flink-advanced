# 抽象级别
Flink提供了不同级别的抽象来开发流/批处理应用程序。

![编程级别的抽象](https://raw.githubusercontent.com/GourdErwa/flink-advanced/master/flink-notes/images/levels_of_abstraction.png)

- 最低级别的抽象仅提供状态流。它通过`Process Function`嵌入到DataStream API中。它允许用户自由地处理一个或多个流中的事件，并使用一致的容错状态。    
此外，用户可以注册事件时间和处理时间回调，从而允许程序实现复杂的计算。

- 实际上，大部分程序通常会使用以 DataStream API（有界/无界数据流）、DataSet API（有界数据集）为代表的核心 API，而并不会使用前述低级抽象接口。  
这些核心 API 为数据处理提供了大量的通用构建模块，包括用户定义的各种各样的变换、连接、聚集、窗口、状态等等。在编程语言中，这些 API 处理的数据类型通常会表现为相应的类的形式。
由于数据流 API 集成了低级处理函数，因此可以通过数据流API为某些特定操作应用低级处理接口。此外，数据集 API 也为诸如循环、迭代之类的有界数据集提供了一些补充的编程原语。

-  Table API 是一种以 Table 为核心地声明式 DSL，能够动态地修改那些表征数据流的表。   
Table API 的工作模式是一种（扩展的）关系型模型：每个 Table 都依附于一个 schema（类似于关系型数据库中的表结构），相应的 API 就可以实现很多类似的操作，例如 select，project，join，group by，aggregate，等等。  
Table API 程序定义的仅仅是如何在逻辑上实现各种程序操作，而不是直接指定程序代码运行的具体步骤。尽管 Table API 可以通过各式各样的自定义函数进行扩展，但是它在表达能力上仍然比不上核心 API，不过 Table API 的优势是在使用上更简练（相对于核心 API 可以减少很多代码）。  
此外，Table API 程序在运行之前也会使用一个优化器对程序进行优化。
由于用户可以在 Table 与 DataStream/DataSet 之间进行无缝切换，程序也可以混合使用 Table API 和 DataStream/DataSet API。

- Flink 提供的最高级接口是 SQL。这个层次的抽象接口和 Table  API 非常相似，包括语法和接口的表现能力，唯一的区别是通过 SQL 查询语言实现程序。    
实际上，SQL 抽象接口和 Table  API 的交互非常紧密，而且 SQL 查询也可以在 Table  API 中定义的表上执行。

# 程序和数据流
Flink程序的基本构建块是流和转换。（请注意，Flink的DataSet API中使用的DataSet也是内部流-稍后将进行更多介绍。）从概念上讲，流是数据记录流（可能永无止境），而转换是将一个或多个流作为一个操作的操作。输入，并产生一个或多个输出流。   

执行时，Flink程序将映射到由流和转换运算符组成的流数据流。每个数据流都以一个或多个源开始，并以一个或多个接收器结束。数据流类似于任意有向无环图（DAG）。尽管可以通过迭代构造来允许特殊形式的循环 ，但是在大多数情况下，为简单起见，我们将对其进行介绍。

![一个DataStream程序及其数据流](https://raw.githubusercontent.com/GourdErwa/flink-advanced/master/flink-notes/images/program_dataflow.png)

程序中的转换与数据流中的运算符之间通常存在一一对应的关系。但是有时，一个转换可能包含多个转换运算符。

数据源和汇聚点记录在流连接器和批处理连接器文档中。转换记录在DataStream运算符和DataSet转换中。

# 并行数据流
Flink中的程序本质上是并行的和分布式的。在执行期间，一个流具有一个或多个流分区，并且每个运算符具有一个或多个运算符子任务。
每个运算子任务与另外一个运算子任务之间都是相互独立的，他们是在不同的线程中运行的，甚至有可能所运行的机器或者容器都完全不同。

运算子任务的数量由运算符的并发数确定。数据流的并发数就是它所生成的运算符的个数。程序中不同的运算符可以有不同等级的并发量。

![并行数据流](https://raw.githubusercontent.com/GourdErwa/flink-advanced/master/flink-notes/images/parallel_dataflow.png)

在两个运算符之间传输数据，流可以按一对一（或转发）模式或重新分配模式：

- 一对一的流（例如，上图中的Source和map（）运算符之间）保留元素的分区和排序。    
这意味着map（）运算符的subtask [1] 将以与Source运算符的subtask [1]产生的相同顺序看到相同的元素。

- 重新分配流（如上面的map（）和keyBy / window之间以及 keyBy / window和Sink之间）会更改流的分区。  
每个操作员子任务都将数据发送到不同的目标子任务，具体取决于所选的转换。实例是 keyBy（） （其通过散列密钥重新分区），广播（） ，或重新平衡（） （其重新分区随机地）。  
在重新分配交换中，元素之间的顺序仅保留在每对发送和接收子任务中（例如map（）的 subtask [1]和map（）的 subtask [2]keyBy / window）。  
因此，在此示例中，保留了每个键内的顺序，但是并行性确实引入了不确定性，即不同键的聚合结果到达接收器的顺序。

有关配置和控制并行性的详细信息，请参见 [并行执行](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/parallel.html) 文档。

# 窗口
汇总事件（例如，计数，总和）在流上的工作方式与批处理中的不同。例如，不可能计算流中的所有元素，因为流通常是无限的（无界）。相反，流上的聚合（计数，总和等）由窗口确定范围，例如“过去5分钟内的计数”或“最近100个元素的总和”。

Windows可以是时间驱动的（例如：每30秒）或数据驱动的（例如：每100个元素）。通常可以区分不同类型的窗口，例如滚动窗口（无重叠）， 滑动窗口（有重叠）和会话窗口（由不活动的间隙打断）。

![时间和计数窗口](https://raw.githubusercontent.com/GourdErwa/flink-advanced/master/flink-notes/images/windows.png)


# 时间
在流式传输程序中引用时间（例如，定义窗口）时，可以引用不同的时间概念：

- **事件时间(Event Time)**是创建事件的时间。通常用事件中的时间戳记来描述，例如由生产传感器或生产服务附加。Flink通过时间戳分配器访问事件时间戳。

- **接收时间(Ingestion time)**是事件在源操作员进入Flink数据流的时间。

- **处理时间(Processing Time)**是每个执行基于时间的操作的操作员的本地时间。

![事件时间，摄取时间和处理时间](https://raw.githubusercontent.com/GourdErwa/flink-advanced/master/flink-notes/images/event_ingestion_processing_time.png)

# 有状态的操作
尽管数据流中的许多操作一次仅查看一个事件（例如事件解析器），但某些操作会记住多个事件的信息（例如窗口运算符）。这些操作称为有状态。

有状态操作的状态以可以被认为是嵌入式键/值存储的方式维护。严格将状态与有状态运算符读取的流一起进行分区和分发。因此，只有在keyBy（）函数之后，才可以在键控流上访问键/值状态，并且仅限于与当前事件的键关联的值。对齐流键和状态键可确保所有状态更新都是本地操作，从而确保了一致性而没有事务开销。这种对齐方式还允许Flink重新分配状态并透明地调整流分区。

![状态和分区](https://raw.githubusercontent.com/GourdErwa/flink-advanced/master/flink-notes/images/state_partitioning.png)

有关更多信息，请参阅关于state的文档。

# 容错检查点
Flink通过结合流重播和检查点来实现容错。检查点与每个输入流中的特定点以及每个运算符的对应状态有关。通过恢复操作员的状态并从检查点开始重放事件，可以在保持一致性（完全一次处理语义）的同时，从检查点恢复流式数据流。

检查点间隔是在执行过程中权衡容错开销与恢复时间（需要重播的事件数）的一种方法。

容错内部的描述提供了有关Flink如何管理检查点和相关主题的更多信息。有关启用和配置检查点的详细信息，请参见checkpointing API文档。

# 串流处理
Flink执行批处理程序，这是流程序的特例，其中流是有界的（元素数量有限）。甲数据集在内部视为数据流。因此，以上概念以同样的方式适用于批处理程序，也适用于流式程序，但有少量例外：

批处理程序的容错功能不使用检查点。通过完全重播流来进行恢复。这是可能的，因为输入是有界的。这将成本更多地推向了恢复，但由于避免了检查点，因此使常规处理的成本降低了。

DataSet API中的状态操作使用简化的内存中/核外数据结构，而不是键/值索引。

DataSet API引入了特殊的同步（基于超步）迭代，仅在有限流上才有可能。有关详细信息，请查看迭代文档。